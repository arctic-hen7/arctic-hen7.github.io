<!DOCTYPE html>
<html lang="en-US" class="light"><head><base href="https://arctic-hen7.github.io/" />
<meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><link rel="stylesheet" href=".perseus/static/tailwind.css"/>
            <script type="module">window.__PERSEUS_RENDER_CFG = `{"contact":"contact","tag/frameworks":"tag","post/bbb3e057-0f97-45a2-aa05-e791802fceee":"post","tag/design":"tag","post/sotto":"post","tag/perseus":"tag","post/7adca2f7-ab95-41e1-8d0d-4bbc020ca018":"post","post/c26d230f-a546-4da0-be18-9857e168d7b9":"post","post/4726b90d-613e-4a45-b419-44cd6ec887a4":"post","post/03ab02d7-f196-46d7-a1f9-d0c951245889":"post","tag/css":"tag","tag/economics":"tag","post/5633d380-fede-4c98-8c31-fc21610e4e5e":"post","tag/linux":"tag","about":"about","tag/dev":"tag","tag/tutorial":"tag","tag/quickfix":"tag","tag/productivity":"tag","tag/project":"tag","tag/explanation":"tag","tag/habits":"tag","shortform":"shortform","tag/rust":"tag","post/496eb33a-c137-4afa-a03c-2f165d522a98":"post","tag/programming":"tag","posts":"posts","post/eede1692-be41-404a-93e8-d4b048db21bc":"post","tag/commentary":"tag","":"","tag/overview":"tag","tag/ai":"tag","tag/webdev":"tag","tag/open-source-admin":"tag","tag/self-development":"tag"}`;

        import init from "https://arctic-hen7.github.io/.perseus/bundle.js";
        async function main() {
            await init("https://arctic-hen7.github.io/.perseus/bundle.wasm");
        }
        main();

        
        

window.__PERSEUS_GLOBAL_STATE = `{"motd":"\\"[W]e should be able to do anything, but want to do only what is good\\" — Montaigne 1.26\\n","woke_up_on_time":true}`;</script>
            <meta itemprop="__perseus_head_boundary" content="">
            
<title>Humans Will Still Have Jobs in 500 Years — Here's Why | The Arctic Circle</title><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css><link rel=stylesheet href=.perseus/static/org.css><meta name=description content="Some basic economics quickly dispells this particular doomsday prediction.">
            <script>
window.__PERSEUS_INITIAL_STATE = `{"author":"Me","contents":"<p>\\nSince the release of ChatGPT, and, more recently, GPT4, which is capable of passing standardised tests with flying colours with just images of the papers, there has been growing public concern regarding the possibility that we&rsquo;re at the bottom of the adoption curve of AI, and that this is just the beginning.\\n</p>\\n\\n<p>\\nTo start with, I think that&rsquo;s probably absolutely right. There has been an explosion of innovation in AI over the last half-year, and that will likely continue, and we are definitely seeing a fundamental shift in the way humans interact with technology. These changes have been incredibly positive in some cases, such as how they facilitated my own development of an app to allow my grandfather to transcribe his memoirs with extraordinary accuracy (using OpenAI&rsquo;s <i>Whisper</i>), but they can also be phenomenally destructive: one has to look no further than the creation of fake news by AI for this.\\n</p>\\n\\n<p>\\nThe question I want to address here, however, is one that has existed for a very long time: will there come a time when machines can replace all human labour? At such a time, what will we all do? Will the machines exterminate us? Will they enslave us? Would they find the universe so totally pointless that they just nuke everything?\\n</p>\\n\\n<p>\\nAs you might have guessed, this question seems to get at the meaning of life here: are we anything without work? I would argue, from a philosophical perspective, that we probably aren&rsquo;t, and I recall Shakespeare&rsquo;s <i>1 Henry IV</i>: &ldquo;if all the year were playijng holidays, / To sport would be as tedious as to work; / But when they seldom come, they wished-for come&rdquo;. However, philosophy unfortunately tends to have a nasty disconnect from reality: very often, we can theoretically model something, but it doesn&rsquo;t have any applicability to the real world (take a squiz at deconstructionism&#x2026;).\\n</p>\\n\\n<p>\\nIn these theoretical uncertainties, in my experience, there is one discipline that comes to the rescue. A discipline oh so theoretical and yet so brutally practical. A discipline that can incorporate both intricate mathematics and some of the most infuriating hand-wavery possible. <b>Economics.</b>\\n</p>\\n\\n<p>\\nTo begin, let&rsquo;s make one thing clear, based on a lovely principle from economics that has a surprisingly philosophical bent to it: <i>in the long run, all factors vary</i>. Basically, we don&rsquo;t know jack about anything past next week, and the whole world could implode for all we know, so, really, modelling anything 500 years from now is bound to be a load of crap.\\n</p>\\n\\n<p>\\nThat said, there are a few rules that hold &rsquo;universally&rsquo;, because they&rsquo;re mathematical, and one of those is the principle of <i>comparative advantage</i>, which underlies modern trade. Essentially, this states that, if you have two agents (i.e. people) in an economy that can produce only two things, say, rabbits and bananas, one will be better at producing one, and the other will be better at producing the other, <i>guaranteed</i>. This may seem unintuitive, after all, why couldn&rsquo;t our first agent, let&rsquo;s call her Alice, be more efficient at producing both? Well, in absolute terms, she could be. Let&rsquo;s take the following production table, which examines how many of each good each agent can produce in, let&rsquo;s say, one day:\\n</p>\\n\\n<table border=\\"2\\" cellspacing=\\"0\\" cellpadding=\\"6\\" rules=\\"groups\\" frame=\\"hsides\\">\\n\\n\\n<colgroup>\\n<col  class=\\"org-left\\" />\\n\\n<col  class=\\"org-right\\" />\\n\\n<col  class=\\"org-right\\" />\\n</colgroup>\\n<thead>\\n<tr>\\n<th scope=\\"col\\" class=\\"org-left\\">Production</th>\\n<th scope=\\"col\\" class=\\"org-right\\">Alice</th>\\n<th scope=\\"col\\" class=\\"org-right\\">Bob</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td class=\\"org-left\\">Bananas</td>\\n<td class=\\"org-right\\">10</td>\\n<td class=\\"org-right\\">6</td>\\n</tr>\\n\\n<tr>\\n<td class=\\"org-left\\">Rabbits</td>\\n<td class=\\"org-right\\">2</td>\\n<td class=\\"org-right\\">1</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n<p>\\nSeems pretty clear who&rsquo;s better, right? Given the same input resources (here, just time), Alice can produce much more of either resource that Bob can produce. Surely, then, she has no reason to even care about Bob&rsquo;s existence? Surely she should produce what she wants and get on with her life?\\n</p>\\n\\n<p>\\nNot quite, and this is one of the most popularly misunderstood principles in economics.\\n</p>\\n\\n<p>\\nTo understand who is more <i>comparatively</i> efficient at producing rabbits and bananas, we need to look to <i>opportunity cost</i>, which is the cost of producing another unit of some good. Let&rsquo;s take the first ten bananas Alice produces, how many rabbits does she give up? That&rsquo;s quite clear, it&rsquo;s two. For five bananas, she gives up one rabbit, and, for one banana, she gives up one-fifth of a rabbit (let&rsquo;s assume production is a continuum, rather than occurring in discrete units, for simplicity). Importantly, the opportunity cost to Alice of producing one rabbit is five bananas, the reciprocal of that of bananas in terms of rabbits.\\n</p>\\n\\n<p>\\nSo, let&rsquo;s repeat the process for Bob and draw up a table of opportunity costs:\\n</p>\\n\\n<table border=\\"2\\" cellspacing=\\"0\\" cellpadding=\\"6\\" rules=\\"groups\\" frame=\\"hsides\\">\\n\\n\\n<colgroup>\\n<col  class=\\"org-left\\" />\\n\\n<col  class=\\"org-left\\" />\\n\\n<col  class=\\"org-left\\" />\\n</colgroup>\\n<thead>\\n<tr>\\n<th scope=\\"col\\" class=\\"org-left\\">OC</th>\\n<th scope=\\"col\\" class=\\"org-left\\">Alice</th>\\n<th scope=\\"col\\" class=\\"org-left\\">Bob</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td class=\\"org-left\\">Bananas</td>\\n<td class=\\"org-left\\">⅕</td>\\n<td class=\\"org-left\\">⅙</td>\\n</tr>\\n\\n<tr>\\n<td class=\\"org-left\\">Rabbits</td>\\n<td class=\\"org-left\\">5</td>\\n<td class=\\"org-left\\">6</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n<p>\\nThis betrays a very interesting relationship: although Alice had <i>absolute advantage</i> in the production of both bananas and rabbits, Bob has a <i>comparative advantage</i> in the production of bananas, because his opportunity cost is lower: he sacrifices less to produce a single banana than Alice does. Therefore, Alice should focus on producing rabbits, while Bob should focus on producing bananas: they should both specialise in the item in which they have the lowest opportunity cost.\\n</p>\\n\\n<p>\\nNow let&rsquo;s call our actors humans and AI. Of course, simplifying the entire economy down to a two-good model is ridiculous, but the point here is that there is <b>always</b> one actor with a comparative advantage in one thing, and another with a comparative advantage in the other. So, if we want to minimise opportunity cost, it is only logical for humans to do some things, and AI to do others. In short, therefore, there is no risk whatsoever that humanity will lose all work and all meaning in life: there will always be <i>something</i> to do.\\n</p>\\n\\n<p>\\nOf course, this isn&rsquo;t exactly the greatest consolation, because, for all we know, that might just be salt mining, and we could feasibly be enslaved and paid nothing for this labour, so preventing such a world evolving should certainly be a priority of innovation in AI, and the controls thereon, but there is no risk of humanity being completely useless in comparison to AI, by basic economics.\\n</p>\\n\\n<p>\\nHowever, I can certainly understand if you&rsquo;re not convinced by this: after all, AI doesn&rsquo;t even take in the same resources as humans, and why can&rsquo;t one agent have a comparative advantage in both goods? Where humans need time, AI needs electricity: if you have a very powerful GPU, the fundamental economic proeprty of AI is that it allows you to trade off time for computational power, which requires the fixed cost of the GPU (or TPU, XPU, YPU, ZPU, or whatever else we&rsquo;ve got by next Tuesday), and then the marginal cost of the electricity required to run a computation. Given that this is very different from the human operational mode of requiring time, we need an example to crystallise things.\\n</p>\\n\\n<p>\\nLet&rsquo;s take something ChatGPT is unreasonably good at: copywriting (i.e. writing promotional material for a brand). If I ask you to do some copywriting for me, your <i>fixed costs</i> (the costs that stay the same no matter how much copy you produce) might be a subscription to Microsoft Office so you can use Word to typeset everything, the cost of a laptop, and then however much it costs me as an employer to buy another desk for you in our lovely and modern &rsquo;open office&rsquo;. Your <i>variable costs</i> (the costs that change depending on the number of units you&rsquo;re producing, usually just the cost of producing an additional unit) are just the time it takes to write a single unit of copy. For ChatGPT, assuming we&rsquo;re using OpenAI&rsquo;s paid API (rather than the free interface, which would be economically irritating), the fixed cost is an internet conection, a printer, etc. (which was probably all required for you to do copywriting), and the variable costs are the API costs. But I&rsquo;ve already hinted at how we can convert between the two: your time is valued according to your wage, and the AI&rsquo;s &rsquo;time&rsquo; is valued according to the API costs: but, for a given unit of monetary input, the AI is much faster as a result of the fact that it takes much less time to write copy. So, let&rsquo;s call our copywriter Cecilia (because Jane and Alice are very busy in other people&rsquo;s examples), and draw up a little table for her and ChatGPT. <i>(Disclaimer: I have no clue what the average productivity of human and AI copywriters are, I&rsquo;m making this up with nice numbers so we can avoid annoying decimals.)</i>\\n</p>\\n\\n<table border=\\"2\\" cellspacing=\\"0\\" cellpadding=\\"6\\" rules=\\"groups\\" frame=\\"hsides\\">\\n\\n\\n<colgroup>\\n<col  class=\\"org-left\\" />\\n\\n<col  class=\\"org-right\\" />\\n\\n<col  class=\\"org-right\\" />\\n</colgroup>\\n<thead>\\n<tr>\\n<th scope=\\"col\\" class=\\"org-left\\">Output</th>\\n<th scope=\\"col\\" class=\\"org-right\\">Cecilia</th>\\n<th scope=\\"col\\" class=\\"org-right\\">ChatGPT</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td class=\\"org-left\\">Copy</td>\\n<td class=\\"org-right\\">5</td>\\n<td class=\\"org-right\\">50</td>\\n</tr>\\n\\n<tr>\\n<td class=\\"org-left\\">Code</td>\\n<td class=\\"org-right\\">1</td>\\n<td class=\\"org-right\\">25</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n<p>\\nNotice that, in order for this model to make any sense, we need to add a second good that can be produced by ChatGPT and Cecilia, and here that will be code, even though Cecilia has barely programmed in her life before. Again, we&rsquo;ll ignore proper units here for simplicity, and say that the input to all this is a &rsquo;wage&rsquo; of $20 over one hour (combining our two inputs into one composite).\\n</p>\\n\\n<p>\\nAgain, ChatGPT has a clear <i>absolute advantage</i> in the production of both goods by a mile, so how can it <i>possibly</i> be efficient to employ Cecilia to do anything at all? Well, let&rsquo;s flop out the opportunity costs:\\n</p>\\n\\n<table border=\\"2\\" cellspacing=\\"0\\" cellpadding=\\"6\\" rules=\\"groups\\" frame=\\"hsides\\">\\n\\n\\n<colgroup>\\n<col  class=\\"org-left\\" />\\n\\n<col  class=\\"org-left\\" />\\n\\n<col  class=\\"org-left\\" />\\n</colgroup>\\n<thead>\\n<tr>\\n<th scope=\\"col\\" class=\\"org-left\\">OC</th>\\n<th scope=\\"col\\" class=\\"org-left\\">Cecilia</th>\\n<th scope=\\"col\\" class=\\"org-left\\">ChatGPT</th>\\n</tr>\\n</thead>\\n<tbody>\\n<tr>\\n<td class=\\"org-left\\">Copy</td>\\n<td class=\\"org-left\\">⅕</td>\\n<td class=\\"org-left\\">½</td>\\n</tr>\\n\\n<tr>\\n<td class=\\"org-left\\">Code</td>\\n<td class=\\"org-left\\">5</td>\\n<td class=\\"org-left\\">2</td>\\n</tr>\\n</tbody>\\n</table>\\n\\n<p>\\nBased on this, Cecilia has a lower opportunity cost in the production of copy, while ChatGPT has a lower opportunity cost in the production of code. So, despite the fact that, in an hour, and for $20, ChatGPT can (in fairyland) produce <i>10x</i> the amount of copy that Cecilia can, and despite the fact that ChatGPT can only produce half as much code as it can copy with the same inputs, the AI should do the coding, and Cecilia should do the copywriting. <b>This is the most efficient possible arrangement of resources.</b>\\n</p>\\n\\n<p>\\nStill don&rsquo;t believe me? Okay, let&rsquo;s break out some graphs. Cecilia&rsquo;s production curve for copy (y-axis) against code (x-axis) is <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>y</mi><mo>=</mo><mo>−</mo><mn>5</mn><mi>x</mi><mo>+</mo><mn>5</mn></mrow><annotation encoding=\\"application/x-tex\\">y = -5x + 5</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.625em;vertical-align:-0.1944em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.03588em;\\">y</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.7278em;vertical-align:-0.0833em;\\"></span><span class=\\"mord\\">−</span><span class=\\"mord\\">5</span><span class=\\"mord mathnormal\\">x</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">+</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">5</span></span></span></span>, while ChatGPT&rsquo;s is <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mi>y</mi><mo>=</mo><mo>−</mo><mn>2</mn><mi>x</mi><mo>+</mo><mn>50</mn></mrow><annotation encoding=\\"application/x-tex\\">y = -2x + 50</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.625em;vertical-align:-0.1944em;\\"></span><span class=\\"mord mathnormal\\" style=\\"margin-right:0.03588em;\\">y</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.7278em;vertical-align:-0.0833em;\\"></span><span class=\\"mord\\">−</span><span class=\\"mord\\">2</span><span class=\\"mord mathnormal\\">x</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">+</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">50</span></span></span></span>. But, if we employ both to produce <i>just code</i>, we would produce <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mn>25</mn><mo>+</mo><mn>2</mn><mo>=</mo><mn>27</mn></mrow><annotation encoding=\\"application/x-tex\\">25 + 2 = 27</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.7278em;vertical-align:-0.0833em;\\"></span><span class=\\"mord\\">25</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">+</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">2</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">27</span></span></span></span> units, while producing <i>just copy</i> would yield <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mn>50</mn><mo>+</mo><mn>5</mn><mo>=</mo><mn>55</mn></mrow><annotation encoding=\\"application/x-tex\\">50 + 5 = 55</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.7278em;vertical-align:-0.0833em;\\"></span><span class=\\"mord\\">50</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span><span class=\\"mbin\\">+</span><span class=\\"mspace\\" style=\\"margin-right:0.2222em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">5</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span><span class=\\"mrel\\">=</span><span class=\\"mspace\\" style=\\"margin-right:0.2778em;\\"></span></span><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:0.6444em;\\"></span><span class=\\"mord\\">55</span></span></span></span> units. So, since we&rsquo;re plotting copy against code, and ChatGPT has a <i>comparative advantage</i> in coding over Cecilia, we&rsquo;ll put its curve first (this is called the <i>principle of low-hanging fruit</i>: we prefer to use the most efficient workers &rsquo;first&rsquo;), shifting it up by 5 units (the extra copy Alice can produce), and we&rsquo;ll shift Alice&rsquo;s curve along by 25 units, since she will start producing once ChatGPT is exhausted (i.e. once we exhaust our budget for it). The highest point on this two-part curve is the point of specialisation, and therefore that is the point of maximum output. <b>It is most efficient to specialise.</b> In the graph below, Cecilia is green, ChatGPT is red, and the combination of the two, called the <i>production possibility curve</i> (PPC) is blue, with the point of specialisation at <span class=\\"katex\\"><span class=\\"katex-mathml\\"><math xmlns=\\"http://www.w3.org/1998/Math/MathML\\"><semantics><mrow><mo stretchy=\\"false\\">(</mo><mn>25</mn><mo separator=\\"true\\">,</mo><mn>5</mn><mo stretchy=\\"false\\">)</mo></mrow><annotation encoding=\\"application/x-tex\\">(25, 5)</annotation></semantics></math></span><span class=\\"katex-html\\" aria-hidden=\\"true\\"><span class=\\"base\\"><span class=\\"strut\\" style=\\"height:1em;vertical-align:-0.25em;\\"></span><span class=\\"mopen\\">(</span><span class=\\"mord\\">25</span><span class=\\"mpunct\\">,</span><span class=\\"mspace\\" style=\\"margin-right:0.1667em;\\"></span><span class=\\"mord\\">5</span><span class=\\"mclose\\">)</span></span></span></span> marked.\\n</p>\\n\\n\\n<div id=\\"org152b6cf\\" class=\\"figure\\">\\n<p><img src=\\"https://i.imgur.com/dNtLKal.png\\" alt=\\"dNtLKal.png\\" />\\n</p>\\n</div>\\n\\n<p>\\nFrom all this, three things are clear: (1) it is really silly to have a totally closed economy, because you&rsquo;re just going to be objectively less efficient at producing than if you traded with people; (2) yes China still needs to trade with the rest of the world, even though they have an absolute advantage in nigh-on everything; and (3) humans will always have <i>something</i> to do. The only exception to the very basic model outlined above is if there is a global limit on production, such that we could not raise ChatGPT&rsquo;s production curve by the 5 units necessary to make this work. If that&rsquo;s true, then one agent&rsquo;s production curve may reach the x-axis on its own, in which case comparative advantage is voided as a principle. However, a global maximum on production, unless enforced by some seriously misguided regulation, is generally not a concern in our case, and so, it can be fairly confidently said, by basic economic principles, that, no matter how advanced and efficient AI becomes, there will always be something for humans to contribute to the world, and therefore some value to be gained from humans and AIs specialising according to their comparative advantage, and, ideally, working in harmonious tandem.\\n</p>\\n\\n<p>\\nQ.E.D.\\n</p>","date":"2023-04-01","description":"Some basic economics quickly dispells this particular doomsday prediction.","id":"5633d380-fede-4c98-8c31-fc21610e4e5e","series":null,"tags":["economics","ai","commentary","explanation"],"title":"Humans Will Still Have Jobs in 500 Years — Here's Why","toc":"<div></div>"}`;
window.__PERSEUS_INITIAL_WIDGET_STATES = `{}`;
window.__PERSEUS_TRANSLATIONS = ``;</script>
            <meta itemprop="__perseus_head_end" content="">
            <script>//</script>
            </head><body class="bg-black text-white"><div id="root"><header data-hk=1.11 class="w-full mb-20 backdrop-blur-lg {}"><div data-hk=1.12 class="sm:p-2 flex justify-between xl:justify-center items-center"><a data-hk=1.13 class="justify-self-start self-center m-3 ml-5 text-lg sm:text-xl text-bold title-font"href=/>The Arctic Site</a><div data-hk=1.14 class="xl:w-[38rem] 2xl:w-[55rem] 3xl:w-[70rem]"></div><div data-hk=1.15 class="md:hidden m-3 mr-5 tham tham-e-spin tham-w-6"><div data-hk=1.16 class=tham-box><div data-hk=1.17 class="tham-inner bg-white"></div></div></div><nav data-hk=1.18 class="hidden md:flex"><ul data-hk=1.19 class="mr-5 flex"><li data-hk=2.0 class="m-3 p-1"><a data-hk=2.1 href>Home</a><li data-hk=2.2 class="m-3 p-1"><a data-hk=2.3 href=about>About</a><li data-hk=2.4 class="m-3 p-1"><a data-hk=2.5 href=posts>The Arctic Circle</a><li data-hk=2.6 class="m-3 p-1"><a data-hk=2.7 href=shortform>The Ice Floes</a></ul></nav></div><nav data-hk=1.20 id=mobile_nav_menu class="sm:p-2 md:hidden w-full text-center justify-center hidden"><ul data-hk=1.21 class=mr-5><li data-hk=3.0 class="m-3 p-1"><a data-hk=3.1 href>Home</a><li data-hk=3.2 class="m-3 p-1"><a data-hk=3.3 href=about>About</a><li data-hk=3.4 class="m-3 p-1"><a data-hk=3.5 href=posts>The Arctic Circle</a><li data-hk=3.6 class="m-3 p-1"><a data-hk=3.7 href=shortform>The Ice Floes</a></ul></nav></header><main data-hk=1.22 class="mt-14 xs:mt-16 sm:mt-20 lg:mt-24"><div data-hk=1.0 class="flex flex-col lg:flex-row-reverse justify-center items-center w-full px-4 sm:px-8 lg:px-10"><h1 data-hk=1.1 class="text-4xl my-3 lg:hidden">Humans Will Still Have Jobs in 500 Years — Here's Why</h1><nav data-hk=1.2 class="styled-prose lg:sticky self-start top-14 xs:top-16 sm:top-20 lg:top-24 max-w-md max-h-[63vh] overflow-y-auto border-l border-neutral-600 pl-4 lg:mx-4 py-3"><div data-hk=1.3 class=max-w-sm><div></div></div></nav><div data-hk=1.4 class=min-w-0><h1 data-hk=1.5 class="text-4xl my-3 text-center hidden lg:block">Humans Will Still Have Jobs in 500 Years — Here's Why</h1><div data-hk=1.6 class="styled-prose lg:max-w-3xl xl:max-w-4xl 2xl:max-w-5xl min-w-0 min-h-0 mb-6"><p>Since the release of ChatGPT, and, more recently, GPT4, which is capable of passing standardised tests with flying colours with just images of the papers, there has been growing public concern regarding the possibility that we’re at the bottom of the adoption curve of AI, and that this is just the beginning.<p>To start with, I think that’s probably absolutely right. There has been an explosion of innovation in AI over the last half-year, and that will likely continue, and we are definitely seeing a fundamental shift in the way humans interact with technology. These changes have been incredibly positive in some cases, such as how they facilitated my own development of an app to allow my grandfather to transcribe his memoirs with extraordinary accuracy (using OpenAI’s <i>Whisper</i>), but they can also be phenomenally destructive: one has to look no further than the creation of fake news by AI for this.<p>The question I want to address here, however, is one that has existed for a very long time: will there come a time when machines can replace all human labour? At such a time, what will we all do? Will the machines exterminate us? Will they enslave us? Would they find the universe so totally pointless that they just nuke everything?<p>As you might have guessed, this question seems to get at the meaning of life here: are we anything without work? I would argue, from a philosophical perspective, that we probably aren’t, and I recall Shakespeare’s <i>1 Henry IV</i>: “if all the year were playijng holidays, / To sport would be as tedious as to work; / But when they seldom come, they wished-for come”. However, philosophy unfortunately tends to have a nasty disconnect from reality: very often, we can theoretically model something, but it doesn’t have any applicability to the real world (take a squiz at deconstructionism…).<p>In these theoretical uncertainties, in my experience, there is one discipline that comes to the rescue. A discipline oh so theoretical and yet so brutally practical. A discipline that can incorporate both intricate mathematics and some of the most infuriating hand-wavery possible. <b>Economics.</b><p>To begin, let’s make one thing clear, based on a lovely principle from economics that has a surprisingly philosophical bent to it: <i>in the long run, all factors vary</i>. Basically, we don’t know jack about anything past next week, and the whole world could implode for all we know, so, really, modelling anything 500 years from now is bound to be a load of crap.<p>That said, there are a few rules that hold ’universally’, because they’re mathematical, and one of those is the principle of <i>comparative advantage</i>, which underlies modern trade. Essentially, this states that, if you have two agents (i.e. people) in an economy that can produce only two things, say, rabbits and bananas, one will be better at producing one, and the other will be better at producing the other, <i>guaranteed</i>. This may seem unintuitive, after all, why couldn’t our first agent, let’s call her Alice, be more efficient at producing both? Well, in absolute terms, she could be. Let’s take the following production table, which examines how many of each good each agent can produce in, let’s say, one day:<table border=2 cellspacing=0 cellpadding=6 rules=groups frame=hsides><colgroup><col class=org-left><col class=org-right><col class=org-right></colgroup><thead><tr><th scope=col class=org-left>Production<th scope=col class=org-right>Alice<th scope=col class=org-right>Bob<tbody><tr><td class=org-left>Bananas<td class=org-right>10<td class=org-right>6<tr><td class=org-left>Rabbits<td class=org-right>2<td class=org-right>1</table><p>Seems pretty clear who’s better, right? Given the same input resources (here, just time), Alice can produce much more of either resource that Bob can produce. Surely, then, she has no reason to even care about Bob’s existence? Surely she should produce what she wants and get on with her life?<p>Not quite, and this is one of the most popularly misunderstood principles in economics.<p>To understand who is more <i>comparatively</i> efficient at producing rabbits and bananas, we need to look to <i>opportunity cost</i>, which is the cost of producing another unit of some good. Let’s take the first ten bananas Alice produces, how many rabbits does she give up? That’s quite clear, it’s two. For five bananas, she gives up one rabbit, and, for one banana, she gives up one-fifth of a rabbit (let’s assume production is a continuum, rather than occurring in discrete units, for simplicity). Importantly, the opportunity cost to Alice of producing one rabbit is five bananas, the reciprocal of that of bananas in terms of rabbits.<p>So, let’s repeat the process for Bob and draw up a table of opportunity costs:<table border=2 cellspacing=0 cellpadding=6 rules=groups frame=hsides><colgroup><col class=org-left><col class=org-left><col class=org-left></colgroup><thead><tr><th scope=col class=org-left>OC<th scope=col class=org-left>Alice<th scope=col class=org-left>Bob<tbody><tr><td class=org-left>Bananas<td class=org-left>⅕<td class=org-left>⅙<tr><td class=org-left>Rabbits<td class=org-left>5<td class=org-left>6</table><p>This betrays a very interesting relationship: although Alice had <i>absolute advantage</i> in the production of both bananas and rabbits, Bob has a <i>comparative advantage</i> in the production of bananas, because his opportunity cost is lower: he sacrifices less to produce a single banana than Alice does. Therefore, Alice should focus on producing rabbits, while Bob should focus on producing bananas: they should both specialise in the item in which they have the lowest opportunity cost.<p>Now let’s call our actors humans and AI. Of course, simplifying the entire economy down to a two-good model is ridiculous, but the point here is that there is <b>always</b> one actor with a comparative advantage in one thing, and another with a comparative advantage in the other. So, if we want to minimise opportunity cost, it is only logical for humans to do some things, and AI to do others. In short, therefore, there is no risk whatsoever that humanity will lose all work and all meaning in life: there will always be <i>something</i> to do.<p>Of course, this isn’t exactly the greatest consolation, because, for all we know, that might just be salt mining, and we could feasibly be enslaved and paid nothing for this labour, so preventing such a world evolving should certainly be a priority of innovation in AI, and the controls thereon, but there is no risk of humanity being completely useless in comparison to AI, by basic economics.<p>However, I can certainly understand if you’re not convinced by this: after all, AI doesn’t even take in the same resources as humans, and why can’t one agent have a comparative advantage in both goods? Where humans need time, AI needs electricity: if you have a very powerful GPU, the fundamental economic proeprty of AI is that it allows you to trade off time for computational power, which requires the fixed cost of the GPU (or TPU, XPU, YPU, ZPU, or whatever else we’ve got by next Tuesday), and then the marginal cost of the electricity required to run a computation. Given that this is very different from the human operational mode of requiring time, we need an example to crystallise things.<p>Let’s take something ChatGPT is unreasonably good at: copywriting (i.e. writing promotional material for a brand). If I ask you to do some copywriting for me, your <i>fixed costs</i> (the costs that stay the same no matter how much copy you produce) might be a subscription to Microsoft Office so you can use Word to typeset everything, the cost of a laptop, and then however much it costs me as an employer to buy another desk for you in our lovely and modern ’open office’. Your <i>variable costs</i> (the costs that change depending on the number of units you’re producing, usually just the cost of producing an additional unit) are just the time it takes to write a single unit of copy. For ChatGPT, assuming we’re using OpenAI’s paid API (rather than the free interface, which would be economically irritating), the fixed cost is an internet conection, a printer, etc. (which was probably all required for you to do copywriting), and the variable costs are the API costs. But I’ve already hinted at how we can convert between the two: your time is valued according to your wage, and the AI’s ’time’ is valued according to the API costs: but, for a given unit of monetary input, the AI is much faster as a result of the fact that it takes much less time to write copy. So, let’s call our copywriter Cecilia (because Jane and Alice are very busy in other people’s examples), and draw up a little table for her and ChatGPT. <i>(Disclaimer: I have no clue what the average productivity of human and AI copywriters are, I’m making this up with nice numbers so we can avoid annoying decimals.)</i><table border=2 cellspacing=0 cellpadding=6 rules=groups frame=hsides><colgroup><col class=org-left><col class=org-right><col class=org-right></colgroup><thead><tr><th scope=col class=org-left>Output<th scope=col class=org-right>Cecilia<th scope=col class=org-right>ChatGPT<tbody><tr><td class=org-left>Copy<td class=org-right>5<td class=org-right>50<tr><td class=org-left>Code<td class=org-right>1<td class=org-right>25</table><p>Notice that, in order for this model to make any sense, we need to add a second good that can be produced by ChatGPT and Cecilia, and here that will be code, even though Cecilia has barely programmed in her life before. Again, we’ll ignore proper units here for simplicity, and say that the input to all this is a ’wage’ of $20 over one hour (combining our two inputs into one composite).<p>Again, ChatGPT has a clear <i>absolute advantage</i> in the production of both goods by a mile, so how can it <i>possibly</i> be efficient to employ Cecilia to do anything at all? Well, let’s flop out the opportunity costs:<table border=2 cellspacing=0 cellpadding=6 rules=groups frame=hsides><colgroup><col class=org-left><col class=org-left><col class=org-left></colgroup><thead><tr><th scope=col class=org-left>OC<th scope=col class=org-left>Cecilia<th scope=col class=org-left>ChatGPT<tbody><tr><td class=org-left>Copy<td class=org-left>⅕<td class=org-left>½<tr><td class=org-left>Code<td class=org-left>5<td class=org-left>2</table><p>Based on this, Cecilia has a lower opportunity cost in the production of copy, while ChatGPT has a lower opportunity cost in the production of code. So, despite the fact that, in an hour, and for $20, ChatGPT can (in fairyland) produce <i>10x</i> the amount of copy that Cecilia can, and despite the fact that ChatGPT can only produce half as much code as it can copy with the same inputs, the AI should do the coding, and Cecilia should do the copywriting. <b>This is the most efficient possible arrangement of resources.</b><p>Still don’t believe me? Okay, let’s break out some graphs. Cecilia’s production curve for copy (y-axis) against code (x-axis) is <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi><mo>=</mo><mo>−</mo><mn>5</mn><mi>x</mi><mo>+</mo><mn>5</mn></mrow><annotation encoding=application/x-tex>y = -5x + 5</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em;></span><span class="mord mathnormal"style=margin-right:0.03588em;>y</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.7278em;vertical-align:-0.0833em;></span><span class=mord>−</span><span class=mord>5</span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>5</span></span></span></span>, while ChatGPT’s is <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>y</mi><mo>=</mo><mo>−</mo><mn>2</mn><mi>x</mi><mo>+</mo><mn>50</mn></mrow><annotation encoding=application/x-tex>y = -2x + 50</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.625em;vertical-align:-0.1944em;></span><span class="mord mathnormal"style=margin-right:0.03588em;>y</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.7278em;vertical-align:-0.0833em;></span><span class=mord>−</span><span class=mord>2</span><span class="mord mathnormal">x</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>50</span></span></span></span>. But, if we employ both to produce <i>just code</i>, we would produce <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>25</mn><mo>+</mo><mn>2</mn><mo>=</mo><mn>27</mn></mrow><annotation encoding=application/x-tex>25 + 2 = 27</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7278em;vertical-align:-0.0833em;></span><span class=mord>25</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>2</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>27</span></span></span></span> units, while producing <i>just copy</i> would yield <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>50</mn><mo>+</mo><mn>5</mn><mo>=</mo><mn>55</mn></mrow><annotation encoding=application/x-tex>50 + 5 = 55</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:0.7278em;vertical-align:-0.0833em;></span><span class=mord>50</span><span class=mspace style=margin-right:0.2222em;></span><span class=mbin>+</span><span class=mspace style=margin-right:0.2222em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>5</span><span class=mspace style=margin-right:0.2778em;></span><span class=mrel>=</span><span class=mspace style=margin-right:0.2778em;></span></span><span class=base><span class=strut style=height:0.6444em;></span><span class=mord>55</span></span></span></span> units. So, since we’re plotting copy against code, and ChatGPT has a <i>comparative advantage</i> in coding over Cecilia, we’ll put its curve first (this is called the <i>principle of low-hanging fruit</i>: we prefer to use the most efficient workers ’first’), shifting it up by 5 units (the extra copy Alice can produce), and we’ll shift Alice’s curve along by 25 units, since she will start producing once ChatGPT is exhausted (i.e. once we exhaust our budget for it). The highest point on this two-part curve is the point of specialisation, and therefore that is the point of maximum output. <b>It is most efficient to specialise.</b> In the graph below, Cecilia is green, ChatGPT is red, and the combination of the two, called the <i>production possibility curve</i> (PPC) is blue, with the point of specialisation at <span class=katex><span class=katex-mathml><math xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mo stretchy=false>(</mo><mn>25</mn><mo separator=true>,</mo><mn>5</mn><mo stretchy=false>)</mo></mrow><annotation encoding=application/x-tex>(25, 5)</annotation></semantics></math></span><span class=katex-html aria-hidden=true><span class=base><span class=strut style=height:1em;vertical-align:-0.25em;></span><span class=mopen>(</span><span class=mord>25</span><span class=mpunct>,</span><span class=mspace style=margin-right:0.1667em;></span><span class=mord>5</span><span class=mclose>)</span></span></span></span> marked.<div id=org152b6cf class=figure><p><img src=https://i.imgur.com/dNtLKal.png alt=dNtLKal.png></div><p>From all this, three things are clear: (1) it is really silly to have a totally closed economy, because you’re just going to be objectively less efficient at producing than if you traded with people; (2) yes China still needs to trade with the rest of the world, even though they have an absolute advantage in nigh-on everything; and (3) humans will always have <i>something</i> to do. The only exception to the very basic model outlined above is if there is a global limit on production, such that we could not raise ChatGPT’s production curve by the 5 units necessary to make this work. If that’s true, then one agent’s production curve may reach the x-axis on its own, in which case comparative advantage is voided as a principle. However, a global maximum on production, unless enforced by some seriously misguided regulation, is generally not a concern in our case, and so, it can be fairly confidently said, by basic economic principles, that, no matter how advanced and efficient AI becomes, there will always be something for humans to contribute to the world, and therefore some value to be gained from humans and AIs specialising according to their comparative advantage, and, ideally, working in harmonious tandem.<p>Q.E.D.</div></div></div><div data-hk=1.7 class="flex flex-col items-center w-full"><ul data-hk=1.8 class="flex justify-center text-center mt-4"><li data-hk=0.0 class=inline-block><a data-hk=0.1 class="block border-4 border-neutral-800 hover:bg-neutral-800 transition-colors duration-150 rounded-lg p-2 px-4 m-2 font-mono flex items-center"href=tag/economics>economics</a><li data-hk=0.2 class=inline-block><a data-hk=0.3 class="block border-4 border-neutral-800 hover:bg-neutral-800 transition-colors duration-150 rounded-lg p-2 px-4 m-2 font-mono flex items-center"href=tag/ai>ai</a><li data-hk=0.4 class=inline-block><a data-hk=0.5 class="block border-4 border-neutral-800 hover:bg-neutral-800 transition-colors duration-150 rounded-lg p-2 px-4 m-2 font-mono flex items-center"href=tag/commentary>commentary</a><li data-hk=0.6 class=inline-block><a data-hk=0.7 class="block border-4 border-neutral-800 hover:bg-neutral-800 transition-colors duration-150 rounded-lg p-2 px-4 m-2 font-mono flex items-center"href=tag/explanation>explanation</a></ul><div data-hk=1.9 class="max-w-prose px-4 mt-8 giscus"></div></div><script data-hk=1.10 src=https://giscus.app/client.js data-repo=arctic-hen7/arctic-hen7.github.io data-repo-id=MDEwOlJlcG9zaXRvcnkzNjc4MTc5Njk= data-category=Comments data-category-id=DIC_kwDOFex08c4CSjuT data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=dark_high_contrast data-lang=en data-loading=lazy crossorigin async></script></main><footer data-hk=1.23 class="w-full flex justify-center py-5 bg-black"><p data-hk=1.24 class="mx-5 text-center">© arctic-hen7 2021-2022</footer></div><div id="__perseus_popup_error"></div></body></html>